# lora-qlora-vllm-inference

This repository contains the Jupyter notebooks used in the following Medium articles:
- [Quantizing Qwen2-VL Models with GPTQModel and Running Efficient Inference with vLLM](https://medium.com/@arunsreekuttan1996/quantizing-qwen2-vl-models-with-gptqmodel-a-complete-guide-for-multi-modal-model-compression-and-f329ea18a17b)
- [Fine-tuning GPTQ Quantized Vision Language Models with LoRA](https://medium.com/@arunsreekuttan1996/fine-tuning-gptq-quantized-vision-language-models-with-lora-733d1e687ff5)
- [Efficiently Serve and Benchmark LoRA Fine-tuned Vision-Language Models using vLLM](https://medium.com/@arunsreekuttan1996/efficiently-serve-and-benchmark-lora-fine-tuned-vision-language-models-using-vllm-3fd8c970b809)

